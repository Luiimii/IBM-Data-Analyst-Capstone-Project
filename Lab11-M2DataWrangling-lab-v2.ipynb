{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform data wrangling tasks to prepare raw data for analysis. Data wrangling involves cleaning, transforming, and organizing data into a structured format suitable for analysis. This lab focuses on tasks like identifying inconsistencies, encoding categorical variables, and feature transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab, you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identify and remove inconsistent data entries.\n",
    "\n",
    "- Encode categorical variables for analysis.\n",
    "\n",
    "- Handle missing values using multiple imputation strategies.\n",
    "\n",
    "- Apply feature scaling and transformation techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intsall the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m128.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m177.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.3.2 pandas-2.3.1 tzdata-2025.2\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (108 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m155.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m136.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.1 kiwisolver-1.4.9 matplotlib-3.10.5 pillow-11.3.0 pyparsing-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import the necessary module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1.1 Import necessary libraries and load the dataset.</h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the dataset is loaded correctly by displaying the first few rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>MainBranch</th>\n",
       "      <th>Age</th>\n",
       "      <th>Employment</th>\n",
       "      <th>RemoteWork</th>\n",
       "      <th>Check</th>\n",
       "      <th>CodingActivities</th>\n",
       "      <th>EdLevel</th>\n",
       "      <th>LearnCode</th>\n",
       "      <th>LearnCodeOnline</th>\n",
       "      <th>...</th>\n",
       "      <th>JobSatPoints_6</th>\n",
       "      <th>JobSatPoints_7</th>\n",
       "      <th>JobSatPoints_8</th>\n",
       "      <th>JobSatPoints_9</th>\n",
       "      <th>JobSatPoints_10</th>\n",
       "      <th>JobSatPoints_11</th>\n",
       "      <th>SurveyLength</th>\n",
       "      <th>SurveyEase</th>\n",
       "      <th>ConvertedCompYearly</th>\n",
       "      <th>JobSat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I am a developer by profession</td>\n",
       "      <td>Under 18 years old</td>\n",
       "      <td>Employed, full-time</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Apples</td>\n",
       "      <td>Hobby</td>\n",
       "      <td>Primary/elementary school</td>\n",
       "      <td>Books / Physical media</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I am a developer by profession</td>\n",
       "      <td>35-44 years old</td>\n",
       "      <td>Employed, full-time</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Apples</td>\n",
       "      <td>Hobby;Contribute to open-source projects;Other...</td>\n",
       "      <td>Bachelor’s degree (B.A., B.S., B.Eng., etc.)</td>\n",
       "      <td>Books / Physical media;Colleague;On the job tr...</td>\n",
       "      <td>Technical documentation;Blogs;Books;Written Tu...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I am a developer by profession</td>\n",
       "      <td>45-54 years old</td>\n",
       "      <td>Employed, full-time</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Apples</td>\n",
       "      <td>Hobby;Contribute to open-source projects;Other...</td>\n",
       "      <td>Master’s degree (M.A., M.S., M.Eng., MBA, etc.)</td>\n",
       "      <td>Books / Physical media;Colleague;On the job tr...</td>\n",
       "      <td>Technical documentation;Blogs;Books;Written Tu...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Appropriate in length</td>\n",
       "      <td>Easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I am learning to code</td>\n",
       "      <td>18-24 years old</td>\n",
       "      <td>Student, full-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apples</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Some college/university study without earning ...</td>\n",
       "      <td>Other online resources (e.g., videos, blogs, f...</td>\n",
       "      <td>Stack Overflow;How-to videos;Interactive tutorial</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Too long</td>\n",
       "      <td>Easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I am a developer by profession</td>\n",
       "      <td>18-24 years old</td>\n",
       "      <td>Student, full-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apples</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Secondary school (e.g. American high school, G...</td>\n",
       "      <td>Other online resources (e.g., videos, blogs, f...</td>\n",
       "      <td>Technical documentation;Blogs;Written Tutorial...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Too short</td>\n",
       "      <td>Easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ResponseId                      MainBranch                 Age  \\\n",
       "0           1  I am a developer by profession  Under 18 years old   \n",
       "1           2  I am a developer by profession     35-44 years old   \n",
       "2           3  I am a developer by profession     45-54 years old   \n",
       "3           4           I am learning to code     18-24 years old   \n",
       "4           5  I am a developer by profession     18-24 years old   \n",
       "\n",
       "            Employment RemoteWork   Check  \\\n",
       "0  Employed, full-time     Remote  Apples   \n",
       "1  Employed, full-time     Remote  Apples   \n",
       "2  Employed, full-time     Remote  Apples   \n",
       "3   Student, full-time        NaN  Apples   \n",
       "4   Student, full-time        NaN  Apples   \n",
       "\n",
       "                                    CodingActivities  \\\n",
       "0                                              Hobby   \n",
       "1  Hobby;Contribute to open-source projects;Other...   \n",
       "2  Hobby;Contribute to open-source projects;Other...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                             EdLevel  \\\n",
       "0                          Primary/elementary school   \n",
       "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
       "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
       "3  Some college/university study without earning ...   \n",
       "4  Secondary school (e.g. American high school, G...   \n",
       "\n",
       "                                           LearnCode  \\\n",
       "0                             Books / Physical media   \n",
       "1  Books / Physical media;Colleague;On the job tr...   \n",
       "2  Books / Physical media;Colleague;On the job tr...   \n",
       "3  Other online resources (e.g., videos, blogs, f...   \n",
       "4  Other online resources (e.g., videos, blogs, f...   \n",
       "\n",
       "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
       "0                                                NaN  ...            NaN   \n",
       "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
       "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
       "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
       "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
       "\n",
       "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
       "0            NaN            NaN            NaN             NaN   \n",
       "1            0.0            0.0            0.0             0.0   \n",
       "2            NaN            NaN            NaN             NaN   \n",
       "3            NaN            NaN            NaN             NaN   \n",
       "4            NaN            NaN            NaN             NaN   \n",
       "\n",
       "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
       "0             NaN                    NaN        NaN                 NaN    NaN  \n",
       "1             0.0                    NaN        NaN                 NaN    NaN  \n",
       "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
       "3             NaN               Too long       Easy                 NaN    NaN  \n",
       "4             NaN              Too short       Easy                 NaN    NaN  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Stack Overflow survey data\n",
    "dataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Explore the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.1 Summarize the dataset by displaying the column data types, counts, and missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65437 entries, 0 to 65436\n",
      "Data columns (total 114 columns):\n",
      " #    Column                          Dtype  \n",
      "---   ------                          -----  \n",
      " 0    ResponseId                      int64  \n",
      " 1    MainBranch                      object \n",
      " 2    Age                             object \n",
      " 3    Employment                      object \n",
      " 4    RemoteWork                      object \n",
      " 5    Check                           object \n",
      " 6    CodingActivities                object \n",
      " 7    EdLevel                         object \n",
      " 8    LearnCode                       object \n",
      " 9    LearnCodeOnline                 object \n",
      " 10   TechDoc                         object \n",
      " 11   YearsCode                       object \n",
      " 12   YearsCodePro                    object \n",
      " 13   DevType                         object \n",
      " 14   OrgSize                         object \n",
      " 15   PurchaseInfluence               object \n",
      " 16   BuyNewTool                      object \n",
      " 17   BuildvsBuy                      object \n",
      " 18   TechEndorse                     object \n",
      " 19   Country                         object \n",
      " 20   Currency                        object \n",
      " 21   CompTotal                       float64\n",
      " 22   LanguageHaveWorkedWith          object \n",
      " 23   LanguageWantToWorkWith          object \n",
      " 24   LanguageAdmired                 object \n",
      " 25   DatabaseHaveWorkedWith          object \n",
      " 26   DatabaseWantToWorkWith          object \n",
      " 27   DatabaseAdmired                 object \n",
      " 28   PlatformHaveWorkedWith          object \n",
      " 29   PlatformWantToWorkWith          object \n",
      " 30   PlatformAdmired                 object \n",
      " 31   WebframeHaveWorkedWith          object \n",
      " 32   WebframeWantToWorkWith          object \n",
      " 33   WebframeAdmired                 object \n",
      " 34   EmbeddedHaveWorkedWith          object \n",
      " 35   EmbeddedWantToWorkWith          object \n",
      " 36   EmbeddedAdmired                 object \n",
      " 37   MiscTechHaveWorkedWith          object \n",
      " 38   MiscTechWantToWorkWith          object \n",
      " 39   MiscTechAdmired                 object \n",
      " 40   ToolsTechHaveWorkedWith         object \n",
      " 41   ToolsTechWantToWorkWith         object \n",
      " 42   ToolsTechAdmired                object \n",
      " 43   NEWCollabToolsHaveWorkedWith    object \n",
      " 44   NEWCollabToolsWantToWorkWith    object \n",
      " 45   NEWCollabToolsAdmired           object \n",
      " 46   OpSysPersonal use               object \n",
      " 47   OpSysProfessional use           object \n",
      " 48   OfficeStackAsyncHaveWorkedWith  object \n",
      " 49   OfficeStackAsyncWantToWorkWith  object \n",
      " 50   OfficeStackAsyncAdmired         object \n",
      " 51   OfficeStackSyncHaveWorkedWith   object \n",
      " 52   OfficeStackSyncWantToWorkWith   object \n",
      " 53   OfficeStackSyncAdmired          object \n",
      " 54   AISearchDevHaveWorkedWith       object \n",
      " 55   AISearchDevWantToWorkWith       object \n",
      " 56   AISearchDevAdmired              object \n",
      " 57   NEWSOSites                      object \n",
      " 58   SOVisitFreq                     object \n",
      " 59   SOAccount                       object \n",
      " 60   SOPartFreq                      object \n",
      " 61   SOHow                           object \n",
      " 62   SOComm                          object \n",
      " 63   AISelect                        object \n",
      " 64   AISent                          object \n",
      " 65   AIBen                           object \n",
      " 66   AIAcc                           object \n",
      " 67   AIComplex                       object \n",
      " 68   AIToolCurrently Using           object \n",
      " 69   AIToolInterested in Using       object \n",
      " 70   AIToolNot interested in Using   object \n",
      " 71   AINextMuch more integrated      object \n",
      " 72   AINextNo change                 object \n",
      " 73   AINextMore integrated           object \n",
      " 74   AINextLess integrated           object \n",
      " 75   AINextMuch less integrated      object \n",
      " 76   AIThreat                        object \n",
      " 77   AIEthics                        object \n",
      " 78   AIChallenges                    object \n",
      " 79   TBranch                         object \n",
      " 80   ICorPM                          object \n",
      " 81   WorkExp                         float64\n",
      " 82   Knowledge_1                     object \n",
      " 83   Knowledge_2                     object \n",
      " 84   Knowledge_3                     object \n",
      " 85   Knowledge_4                     object \n",
      " 86   Knowledge_5                     object \n",
      " 87   Knowledge_6                     object \n",
      " 88   Knowledge_7                     object \n",
      " 89   Knowledge_8                     object \n",
      " 90   Knowledge_9                     object \n",
      " 91   Frequency_1                     object \n",
      " 92   Frequency_2                     object \n",
      " 93   Frequency_3                     object \n",
      " 94   TimeSearching                   object \n",
      " 95   TimeAnswering                   object \n",
      " 96   Frustration                     object \n",
      " 97   ProfessionalTech                object \n",
      " 98   ProfessionalCloud               object \n",
      " 99   ProfessionalQuestion            object \n",
      " 100  Industry                        object \n",
      " 101  JobSatPoints_1                  float64\n",
      " 102  JobSatPoints_4                  float64\n",
      " 103  JobSatPoints_5                  float64\n",
      " 104  JobSatPoints_6                  float64\n",
      " 105  JobSatPoints_7                  float64\n",
      " 106  JobSatPoints_8                  float64\n",
      " 107  JobSatPoints_9                  float64\n",
      " 108  JobSatPoints_10                 float64\n",
      " 109  JobSatPoints_11                 float64\n",
      " 110  SurveyLength                    object \n",
      " 111  SurveyEase                      object \n",
      " 112  ConvertedCompYearly             float64\n",
      " 113  JobSat                          float64\n",
      "dtypes: float64(13), int64(1), object(100)\n",
      "memory usage: 56.9+ MB\n",
      "\n",
      "Number of missing values per column:\n",
      "RemoteWork                        10631\n",
      "CodingActivities                  10971\n",
      "EdLevel                            4653\n",
      "LearnCode                          4949\n",
      "LearnCodeOnline                   16200\n",
      "TechDoc                           24540\n",
      "YearsCode                          5568\n",
      "YearsCodePro                      13827\n",
      "DevType                            5992\n",
      "OrgSize                           17957\n",
      "PurchaseInfluence                 18031\n",
      "BuyNewTool                        20256\n",
      "BuildvsBuy                        22079\n",
      "TechEndorse                       21769\n",
      "Country                            6507\n",
      "Currency                          18753\n",
      "CompTotal                         31697\n",
      "LanguageHaveWorkedWith             5692\n",
      "LanguageWantToWorkWith             9685\n",
      "LanguageAdmired                   14565\n",
      "DatabaseHaveWorkedWith            15183\n",
      "DatabaseWantToWorkWith            22879\n",
      "DatabaseAdmired                   26880\n",
      "PlatformHaveWorkedWith            23071\n",
      "PlatformWantToWorkWith            30905\n",
      "PlatformAdmired                   34060\n",
      "WebframeHaveWorkedWith            20276\n",
      "WebframeWantToWorkWith            26902\n",
      "WebframeAdmired                   30494\n",
      "EmbeddedHaveWorkedWith            43223\n",
      "EmbeddedWantToWorkWith            47837\n",
      "EmbeddedAdmired                   48704\n",
      "MiscTechHaveWorkedWith            25994\n",
      "MiscTechWantToWorkWith            32473\n",
      "MiscTechAdmired                   35841\n",
      "ToolsTechHaveWorkedWith           12955\n",
      "ToolsTechWantToWorkWith           19353\n",
      "ToolsTechAdmired                  21440\n",
      "NEWCollabToolsHaveWorkedWith       7845\n",
      "NEWCollabToolsWantToWorkWith      13350\n",
      "NEWCollabToolsAdmired             14726\n",
      "OpSysPersonal use                  7263\n",
      "OpSysProfessional use             12464\n",
      "OfficeStackAsyncHaveWorkedWith    17344\n",
      "OfficeStackAsyncWantToWorkWith    26471\n",
      "OfficeStackAsyncAdmired           28233\n",
      "OfficeStackSyncHaveWorkedWith      9892\n",
      "OfficeStackSyncWantToWorkWith     18726\n",
      "OfficeStackSyncAdmired            20725\n",
      "AISearchDevHaveWorkedWith         20984\n",
      "AISearchDevWantToWorkWith         28736\n",
      "AISearchDevAdmired                29894\n",
      "NEWSOSites                         5151\n",
      "SOVisitFreq                        5901\n",
      "SOAccount                          5877\n",
      "SOPartFreq                        20200\n",
      "SOHow                              6475\n",
      "SOComm                             6274\n",
      "AISelect                           4530\n",
      "AISent                            19564\n",
      "AIBen                             28543\n",
      "AIAcc                             28135\n",
      "AIComplex                         28416\n",
      "AIToolCurrently Using             30365\n",
      "AIToolInterested in Using         34746\n",
      "AIToolNot interested in Using     41023\n",
      "AINextMuch more integrated        51999\n",
      "AINextNo change                   52939\n",
      "AINextMore integrated             41009\n",
      "AINextLess integrated             63082\n",
      "AINextMuch less integrated        64289\n",
      "AIThreat                          20748\n",
      "AIEthics                          23889\n",
      "AIChallenges                      27906\n",
      "TBranch                           20960\n",
      "ICorPM                            35636\n",
      "WorkExp                           35779\n",
      "Knowledge_1                       36773\n",
      "Knowledge_2                       37416\n",
      "Knowledge_3                       37342\n",
      "Knowledge_4                       37407\n",
      "Knowledge_5                       37557\n",
      "Knowledge_6                       37573\n",
      "Knowledge_7                       37659\n",
      "Knowledge_8                       37679\n",
      "Knowledge_9                       37802\n",
      "Frequency_1                       37068\n",
      "Frequency_2                       37073\n",
      "Frequency_3                       37727\n",
      "TimeSearching                     36526\n",
      "TimeAnswering                     36593\n",
      "Frustration                       37186\n",
      "ProfessionalTech                  37673\n",
      "ProfessionalCloud                 36946\n",
      "ProfessionalQuestion              36630\n",
      "Industry                          36579\n",
      "JobSatPoints_1                    36113\n",
      "JobSatPoints_4                    36044\n",
      "JobSatPoints_5                    36026\n",
      "JobSatPoints_6                    35987\n",
      "JobSatPoints_7                    35989\n",
      "JobSatPoints_8                    35981\n",
      "JobSatPoints_9                    35981\n",
      "JobSatPoints_10                   35987\n",
      "JobSatPoints_11                   35992\n",
      "SurveyLength                       9255\n",
      "SurveyEase                         9199\n",
      "ConvertedCompYearly               42002\n",
      "JobSat                            36311\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "df.info(verbose=True)\n",
    "print()\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Number of missing values per column:\")\n",
    "print(missing_values[missing_values > 0].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.2 Generate basic statistics for numerical columns.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>CompTotal</th>\n",
       "      <th>WorkExp</th>\n",
       "      <th>JobSatPoints_1</th>\n",
       "      <th>JobSatPoints_4</th>\n",
       "      <th>JobSatPoints_5</th>\n",
       "      <th>JobSatPoints_6</th>\n",
       "      <th>JobSatPoints_7</th>\n",
       "      <th>JobSatPoints_8</th>\n",
       "      <th>JobSatPoints_9</th>\n",
       "      <th>JobSatPoints_10</th>\n",
       "      <th>JobSatPoints_11</th>\n",
       "      <th>ConvertedCompYearly</th>\n",
       "      <th>JobSat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>65437.000000</td>\n",
       "      <td>3.374000e+04</td>\n",
       "      <td>29658.000000</td>\n",
       "      <td>29324.000000</td>\n",
       "      <td>29393.000000</td>\n",
       "      <td>29411.000000</td>\n",
       "      <td>29450.000000</td>\n",
       "      <td>29448.00000</td>\n",
       "      <td>29456.000000</td>\n",
       "      <td>29456.000000</td>\n",
       "      <td>29450.000000</td>\n",
       "      <td>29445.000000</td>\n",
       "      <td>2.343500e+04</td>\n",
       "      <td>29126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32719.000000</td>\n",
       "      <td>2.963841e+145</td>\n",
       "      <td>11.466957</td>\n",
       "      <td>18.581094</td>\n",
       "      <td>7.522140</td>\n",
       "      <td>10.060857</td>\n",
       "      <td>24.343232</td>\n",
       "      <td>22.96522</td>\n",
       "      <td>20.278165</td>\n",
       "      <td>16.169432</td>\n",
       "      <td>10.955713</td>\n",
       "      <td>9.953948</td>\n",
       "      <td>8.615529e+04</td>\n",
       "      <td>6.935041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18890.179119</td>\n",
       "      <td>5.444117e+147</td>\n",
       "      <td>9.168709</td>\n",
       "      <td>25.966221</td>\n",
       "      <td>18.422661</td>\n",
       "      <td>21.833836</td>\n",
       "      <td>27.089360</td>\n",
       "      <td>27.01774</td>\n",
       "      <td>26.108110</td>\n",
       "      <td>24.845032</td>\n",
       "      <td>22.906263</td>\n",
       "      <td>21.775652</td>\n",
       "      <td>1.867570e+05</td>\n",
       "      <td>2.088259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16360.000000</td>\n",
       "      <td>6.000000e+04</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.271200e+04</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32719.000000</td>\n",
       "      <td>1.100000e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.500000e+04</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49078.000000</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.079715e+05</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65437.000000</td>\n",
       "      <td>1.000000e+150</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.625660e+07</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ResponseId      CompTotal       WorkExp  JobSatPoints_1  \\\n",
       "count  65437.000000   3.374000e+04  29658.000000    29324.000000   \n",
       "mean   32719.000000  2.963841e+145     11.466957       18.581094   \n",
       "std    18890.179119  5.444117e+147      9.168709       25.966221   \n",
       "min        1.000000   0.000000e+00      0.000000        0.000000   \n",
       "25%    16360.000000   6.000000e+04      4.000000        0.000000   \n",
       "50%    32719.000000   1.100000e+05      9.000000       10.000000   \n",
       "75%    49078.000000   2.500000e+05     16.000000       22.000000   \n",
       "max    65437.000000  1.000000e+150     50.000000      100.000000   \n",
       "\n",
       "       JobSatPoints_4  JobSatPoints_5  JobSatPoints_6  JobSatPoints_7  \\\n",
       "count    29393.000000    29411.000000    29450.000000     29448.00000   \n",
       "mean         7.522140       10.060857       24.343232        22.96522   \n",
       "std         18.422661       21.833836       27.089360        27.01774   \n",
       "min          0.000000        0.000000        0.000000         0.00000   \n",
       "25%          0.000000        0.000000        0.000000         0.00000   \n",
       "50%          0.000000        0.000000       20.000000        15.00000   \n",
       "75%          5.000000       10.000000       30.000000        30.00000   \n",
       "max        100.000000      100.000000      100.000000       100.00000   \n",
       "\n",
       "       JobSatPoints_8  JobSatPoints_9  JobSatPoints_10  JobSatPoints_11  \\\n",
       "count    29456.000000    29456.000000     29450.000000     29445.000000   \n",
       "mean        20.278165       16.169432        10.955713         9.953948   \n",
       "std         26.108110       24.845032        22.906263        21.775652   \n",
       "min          0.000000        0.000000         0.000000         0.000000   \n",
       "25%          0.000000        0.000000         0.000000         0.000000   \n",
       "50%         10.000000        5.000000         0.000000         0.000000   \n",
       "75%         25.000000       20.000000        10.000000        10.000000   \n",
       "max        100.000000      100.000000       100.000000       100.000000   \n",
       "\n",
       "       ConvertedCompYearly        JobSat  \n",
       "count         2.343500e+04  29126.000000  \n",
       "mean          8.615529e+04      6.935041  \n",
       "std           1.867570e+05      2.088259  \n",
       "min           1.000000e+00      0.000000  \n",
       "25%           3.271200e+04      6.000000  \n",
       "50%           6.500000e+04      7.000000  \n",
       "75%           1.079715e+05      8.000000  \n",
       "max           1.625660e+07     10.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identifying and Removing Inconsistencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.1 Identify inconsistent or irrelevant entries in specific columns (e.g., Country).</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate values within dataset: 0\n",
      "Missing values for Country column: 6507\n",
      "Most frequent country is: United States of America\n",
      "Missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "num_duplicates = df.duplicated().sum()\n",
    "print(\"Duplicate values within dataset:\", num_duplicates)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "missing_values = df[\"Country\"].isnull().sum()\n",
    "print(\"Missing values for Country column:\", missing_values)\n",
    "\n",
    "most_frequent_country = df['Country'].mode()[0]\n",
    "df[\"Country\"] = df[\"Country\"].fillna(most_frequent_country)\n",
    "print(\"Most frequent country is:\", most_frequent_country)\n",
    "print(\"Missing values after imputation:\", df[\"Country\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.2 Standardize entries in columns like Country or EdLevel by mapping inconsistent values to a consistent format.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNTRY MAPPING:\n",
      "\n",
      "['United States' 'United Kingdom' 'Canada' 'Norway' 'Uzbekistan' 'Serbia'\n",
      " 'Poland' 'Philippines' 'Bulgaria' 'Switzerland' 'India' 'Germany'\n",
      " 'Ireland' 'Italy' 'Ukraine' 'Australia' 'Brazil' 'Japan' 'Austria' 'Iran'\n",
      " 'France' 'Saudi Arabia' 'Romania' 'Turkey' 'Nepal' 'Algeria' 'Sweden'\n",
      " 'Netherlands' 'Croatia' 'Pakistan' 'Czech Republic'\n",
      " 'Republic of North Macedonia' 'Finland' 'Slovakia' 'Russia' 'Greece'\n",
      " 'Israel' 'Belgium' 'Mexico' 'Tanzania' 'Hungary' 'Argentina' 'Portugal'\n",
      " 'Sri Lanka' 'Latvia' 'China' 'Singapore' 'Lebanon' 'Spain' 'South Africa'\n",
      " 'Lithuania' 'Vietnam' 'Dominican Republic' 'Indonesia' 'Kosovo' 'Morocco'\n",
      " 'Taiwan' 'Georgia' 'San Marino' 'Tunisia' 'Bangladesh' 'Nigeria'\n",
      " 'Liechtenstein' 'Denmark' 'Ecuador' 'Malaysia' 'Albania' 'Azerbaijan'\n",
      " 'Chile' 'Ghana' 'Peru' 'Bolivia' 'Egypt' 'Luxembourg' 'Montenegro'\n",
      " 'Cyprus' 'Paraguay' 'Kazakhstan' 'Slovenia' 'Jordan' 'Venezuela'\n",
      " 'Costa Rica' 'Jamaica' 'Thailand' 'Nicaragua' 'Myanmar' 'South Korea'\n",
      " 'Rwanda' 'Bosnia and Herzegovina' 'Benin' 'El Salvador' 'Zimbabwe'\n",
      " 'Afghanistan' 'Estonia' 'Malta' 'Uruguay' 'Belarus' 'Colombia'\n",
      " 'Republic of Moldova' 'Isle of Man' 'Nomadic' 'New Zealand' 'Palestine'\n",
      " 'Armenia' 'United Arab Emirates' 'Maldives' 'Ethiopia' 'Fiji' 'Guatemala'\n",
      " 'Uganda' 'Turkmenistan' 'Mauritius' 'Kenya' 'Cuba' 'Gabon' 'Bahamas'\n",
      " 'Iceland' 'Honduras' 'Hong Kong' 'Laos' 'Mongolia' 'Cambodia'\n",
      " 'Madagascar' 'Angola' 'Democratic Republic of the Congo'\n",
      " 'Syrian Arab Republic' 'Iraq' 'Namibia' 'Senegal' 'Kyrgyzstan' 'Zambia'\n",
      " 'Swaziland' \"Côte d'Ivoire\" 'Kuwait' 'Tajikistan' 'Burundi'\n",
      " 'Trinidad and Tobago' 'Mauritania' 'Sierra Leone' 'Panama' 'Somalia'\n",
      " 'North Korea' 'Dominica' 'Guyana' 'Togo' 'Oman' 'Barbados' 'Andorra'\n",
      " 'Qatar' 'Sudan' 'Cameroon' 'Papua New Guinea' 'Bahrain' 'Yemen' 'Malawi'\n",
      " 'Burkina Faso' 'Congo, Republic of the...' 'Botswana' 'Guinea-Bissau'\n",
      " 'Mozambique' 'Central African Republic' 'Equatorial Guinea' 'Suriname'\n",
      " 'Belize' 'Libyan Arab Jamahiriya' 'Cape Verde' 'Brunei Darussalam'\n",
      " 'Bhutan' 'Guinea' 'Niger' 'Antigua and Barbuda' 'Mali' 'Samoa' 'Lesotho'\n",
      " 'Saint Kitts and Nevis' 'Monaco' 'Micronesia' 'Haiti' 'Nauru' 'Liberia'\n",
      " 'Chad' 'Djibouti' 'Solomon Islands']\n",
      "\n",
      "EDLEVEL MAPPING:\n",
      "\n",
      "Missing values for EdLevel column: 4653\n",
      "Most frequent EdLevel is: Bachelor’s degree (B.A., B.S., B.Eng., etc.)\n",
      "Missing values after imputation: 0\n",
      "\n",
      "['Primary School' \"Bachelor's Degree\" \"Master's Degree\"\n",
      " 'Some College/University' 'High School' 'Professional Degree'\n",
      " 'Associate Degree' 'Other']\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "print(\"COUNTRY MAPPING:\\n\")\n",
    "country_mapping = {\n",
    "    'Iran, Islamic Republic of...': 'Iran',\n",
    "    'Venezuela, Bolivarian Republic of...': 'Venezuela',\n",
    "    'Viet Nam': 'Vietnam',\n",
    "    'United States of America': 'United States',\n",
    "    'Hong Kong (S.A.R.)': 'Hong Kong',\n",
    "    'United Kingdom of Great Britain and Northern Ireland': 'United Kingdom',\n",
    "    'Democratic People\\'s Republic of Korea': 'North Korea',\n",
    "    'Republic of Korea': 'South Korea',\n",
    "    'Micronesia, Federated States of...': 'Micronesia',\n",
    "    'Lao People\\'s Democratic Republic': 'Laos',\n",
    "    'Russian Federation': 'Russia',\n",
    "    'United Republic of Tanzania': 'Tanzania'\n",
    "}\n",
    "df[\"Country\"] = df[\"Country\"].replace(country_mapping)\n",
    "print(df[\"Country\"].unique())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"EDLEVEL MAPPING:\\n\")\n",
    "missing_EdLevel = df[\"EdLevel\"].isnull().sum()\n",
    "print(\"Missing values for EdLevel column:\", missing_EdLevel)\n",
    "most_frequent_EdLevel = df[\"EdLevel\"].mode()[0]\n",
    "df[\"EdLevel\"] = df[\"EdLevel\"].fillna(most_frequent_EdLevel)\n",
    "print(\"Most frequent EdLevel is:\", most_frequent_EdLevel)\n",
    "print(\"Missing values after imputation:\", df[\"EdLevel\"].isnull().sum())\n",
    "print()\n",
    "EdLevel_mapping = {\n",
    "    'Primary/elementary school': 'Primary School',\n",
    "    'Bachelor’s degree (B.A., B.S., B.Eng., etc.)': 'Bachelor\\'s Degree',\n",
    "    'Master’s degree (M.A., M.S., M.Eng., MBA, etc.)': 'Master\\'s Degree',\n",
    "    'Some college/university study without earning a degree': 'Some College/University',\n",
    "    'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)': 'High School',\n",
    "    'Professional degree (JD, MD, Ph.D, Ed.D, etc.)': 'Professional Degree',\n",
    "    'Associate degree (A.A., A.S., etc.)': 'Associate Degree',\n",
    "    'Something else': 'Other'\n",
    "}\n",
    "df[\"EdLevel\"] = df[\"EdLevel\"].replace(EdLevel_mapping)\n",
    "print(df[\"EdLevel\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encoding Categorical Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>4.1 Encode the Employment column using one-hot encoding.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "def simplify_employment(value):\n",
    "    value = value.lower()\n",
    "    if 'employed, full-time' in value:\n",
    "        return 'Employed, Full-Time'\n",
    "    elif 'employed, part-time' in value:\n",
    "        return 'Employed, Part-Time'\n",
    "    elif 'student, full-time' in value:\n",
    "        return 'Student, Full-Time'\n",
    "    elif 'student, part-time' in value:\n",
    "        return 'Student, Part-Time'\n",
    "    elif 'self-employed' in value or 'freelancer' in value:\n",
    "        return 'Self-Employed'\n",
    "    elif 'unemployed' in value or 'not employed' in value:\n",
    "        return 'Unemployed'\n",
    "    elif 'retired' in value:\n",
    "        return 'Retired'\n",
    "    elif 'prefer not' in value:\n",
    "        return 'Prefer Not to Say'\n",
    "    else:\n",
    "        return 'Other'\n",
    "df[\"Employment_Clean\"] = df[\"Employment\"].apply(simplify_employment)\n",
    "employment_encoded = pd.get_dummies(df['Employment_Clean'], prefix='Employment_Clean')\n",
    "df = pd.concat([df, employment_encoded], axis=1)\n",
    "df.drop('Employment', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.1 Identify columns with the highest number of missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top columns with the highest number of missing values:\n",
      "AINextMuch less integrated       64289\n",
      "AINextLess integrated            63082\n",
      "AINextNo change                  52939\n",
      "AINextMuch more integrated       51999\n",
      "EmbeddedAdmired                  48704\n",
      "EmbeddedWantToWorkWith           47837\n",
      "EmbeddedHaveWorkedWith           43223\n",
      "ConvertedCompYearly              42002\n",
      "AIToolNot interested in Using    41023\n",
      "AINextMore integrated            41009\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_counts_sorted = missing_counts.sort_values(ascending=False)\n",
    "print(\"Top columns with the highest number of missing values:\")\n",
    "print(missing_counts_sorted.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.2 Impute missing values in numerical columns (e.g., `ConvertedCompYearly`) with the mean or median.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 42002\n",
      "Median: 65000.0\n",
      "Missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "missing_comp = df[\"ConvertedCompYearly\"].isnull().sum()\n",
    "print(\"Missing values:\", missing_comp)\n",
    "median_comp = df[\"ConvertedCompYearly\"].median()\n",
    "df[\"ConvertedCompYearly\"] = df[\"ConvertedCompYearly\"].fillna(median_comp)\n",
    "print(\"Median:\", median_comp)\n",
    "print(\"Missing values after imputation:\", df[\"ConvertedCompYearly\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.3 Impute missing values in categorical columns (e.g., `RemoteWork`) with the most frequent value.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 10631\n",
      "Most frequent RemoteWork value: Hybrid (some remote, some in-person)\n",
      "Missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "missing_RemoteWork = df[\"RemoteWork\"].isnull().sum()\n",
    "print(\"Missing values:\", missing_RemoteWork)\n",
    "most_frequent = df[\"RemoteWork\"].mode()[0]\n",
    "print(\"Most frequent RemoteWork value:\", most_frequent)\n",
    "df[\"RemoteWork\"] = df[\"RemoteWork\"].fillna(most_frequent)\n",
    "print(\"Missing values after imputation:\", df[\"RemoteWork\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature Scaling and Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.1 Apply Min-Max Scaling to normalize the `ConvertedCompYearly` column.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConvertedCompYearly</th>\n",
       "      <th>ConvertedCompYearly_MinMax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65000.0</td>\n",
       "      <td>0.003998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65000.0</td>\n",
       "      <td>0.003998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65000.0</td>\n",
       "      <td>0.003998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65000.0</td>\n",
       "      <td>0.003998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65000.0</td>\n",
       "      <td>0.003998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ConvertedCompYearly  ConvertedCompYearly_MinMax\n",
       "0              65000.0                    0.003998\n",
       "1              65000.0                    0.003998\n",
       "2              65000.0                    0.003998\n",
       "3              65000.0                    0.003998\n",
       "4              65000.0                    0.003998"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write your code here\n",
    "min_value = df[\"ConvertedCompYearly\"].min()\n",
    "max_value = df[\"ConvertedCompYearly\"].max()\n",
    "df[\"ConvertedCompYearly_MinMax\"] = (df[\"ConvertedCompYearly\"] - min_value) / (max_value - min_value)\n",
    "df[[\"ConvertedCompYearly\", \"ConvertedCompYearly_MinMax\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.2 Log-transform the ConvertedCompYearly column to reduce skewness.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConvertedCompYearly</th>\n",
       "      <th>ConvertedCompYearly_Log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65000.0</td>\n",
       "      <td>11.082158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65000.0</td>\n",
       "      <td>11.082158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65000.0</td>\n",
       "      <td>11.082158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65000.0</td>\n",
       "      <td>11.082158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65000.0</td>\n",
       "      <td>11.082158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ConvertedCompYearly  ConvertedCompYearly_Log\n",
       "0              65000.0                11.082158\n",
       "1              65000.0                11.082158\n",
       "2              65000.0                11.082158\n",
       "3              65000.0                11.082158\n",
       "4              65000.0                11.082158"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write your code here\n",
    "import numpy as np\n",
    "df[\"ConvertedCompYearly_Log\"] = np.log1p(df[\"ConvertedCompYearly\"])\n",
    "df[[\"ConvertedCompYearly\", \"ConvertedCompYearly_Log\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>7.1 Create a new column `ExperienceLevel` based on the `YearsCodePro` column:</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 0\n",
      "Median: 7.0\n",
      "Missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "df[\"YearsCodePro\"] = df[\"YearsCodePro\"].replace({\n",
    "    'Less than 1 year': 0,\n",
    "    'More than 50 years': 51\n",
    "})\n",
    "\n",
    "df[\"YearsCodePro\"] = pd.to_numeric(df[\"YearsCodePro\"], errors='coerce')\n",
    "\n",
    "missing_years = df[\"YearsCodePro\"].isnull().sum()\n",
    "print(\"Missing values:\", missing_years)\n",
    "median_years = df[\"YearsCodePro\"].median()\n",
    "print(\"Median:\", median_years)\n",
    "df[\"YearsCodePro\"] = df[\"YearsCodePro\"].fillna(median_years)\n",
    "print(\"Missing values after imputation:\", df[\"YearsCodePro\"].isnull().sum())\n",
    "\n",
    "def classify_experience(years):\n",
    "    if years <= 2:\n",
    "        return \"Beginner\"\n",
    "    elif years <= 5:\n",
    "        return \"Intermediate\"\n",
    "    elif years <= 10:\n",
    "        return \"Advanced\"\n",
    "    else:\n",
    "        return \"Expert\"\n",
    "df[\"ExperienceLevel\"] = df[\"YearsCodePro\"].apply(classify_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExperienceLevel\n",
       "Advanced        26480\n",
       "Expert          18460\n",
       "Intermediate    10834\n",
       "Beginner         9663\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ExperienceLevel\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you:\n",
    "\n",
    "- Explored the dataset to identify inconsistencies and missing values.\n",
    "\n",
    "- Encoded categorical variables for analysis.\n",
    "\n",
    "- Handled missing values using imputation techniques.\n",
    "\n",
    "- Normalized and transformed numerical data to prepare it for analysis.\n",
    "\n",
    "- Engineered a new feature to enhance data interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "1e8e234f19fd098e27b0518a87f18de690e1c51f1d3263d5690927d19971251e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
